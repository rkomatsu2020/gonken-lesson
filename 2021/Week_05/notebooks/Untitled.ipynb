{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../pyfiles/\")\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225])\n",
    "transform = {}\n",
    "transform[\"train\"] = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "    \n",
    "transform[\"test\"] = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda2numpy(x):\n",
    "    return x.detach().to(\"cpu\").numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Fashion_MNIST(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, classes, mode=\"train\", transform=None, balance=[0.8,0.1,0.1]):\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        images = {} \n",
    "        labels = {}\n",
    "        \n",
    "        for cl in classes:\n",
    "            path_list = glob.glob(root + f\"{cl}/*\")\n",
    "            path_list.sort()\n",
    "            train_num = int(balance[0]*len(path_list))\n",
    "            val_num = int(balance[1]*len(path_list))\n",
    "            test_num = int(balance[2]*len(path_list))\n",
    "            if mode==\"train\":\n",
    "                path_list = path_list[:train_num]\n",
    "            elif mode==\"val\":\n",
    "                path_list = path_list[train_num:train_num+val_num]\n",
    "            elif mode==\"test\":\n",
    "                path_list = path_list[-test_num:]\n",
    "            images[str(cl)] = path_list\n",
    "            labels[str(cl)] = [cl]*len(path_list)\n",
    "            \n",
    "        # combine them together\n",
    "        for label in classes:\n",
    "            for image, label in zip(images[str(label)], labels[str(label)]):\n",
    "                self.images.append(image)\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        with open(image, 'rb') as f:\n",
    "            image = Image.open(f)\n",
    "            image = image.convert(\"L\")\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        image = min_max(image, mean0=True)\n",
    "#         image = torch.Tensor(np.reshape(min_max(image, mean0=False), (1, image.shape[0], -1)))\n",
    "            \n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../fashion_dataset1/\"\n",
    "classes = range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset_Fashion_MNIST(root, classes, \"train\", transform[\"train\"])\n",
    "dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, label = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1214bda30>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image_from_numpy(cuda2numpy(x[np.newaxis]))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the model consists of 3 convolutional blocks and 3 fully connected layers.\n",
    "- each convolutional block has a convolutional layer and a max pooling layer.\n",
    "- ReLU is employed as an activation function except for the final layer.\n",
    "- Ofcource, this is classification task, so you should use Softmax function in the last computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.reshape(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, nch_in, nch_out, kernel, activation=\"ReLU\"):\n",
    "        super(ConvolutionalBlock, self).__init__()\n",
    "        layers = [\n",
    "            nn.Conv2d(nch_in, nch_out, kernel_size=kernel, stride=1, padding=int((kernel-1)/2)),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        ]\n",
    "        if activation==\"ReLU\":\n",
    "            layers.append(nn.ReLU())\n",
    "        elif activation==\"Tanh\":\n",
    "            layers.append(nn.Tanh())\n",
    "        elif activation==\"Sigmoid\":\n",
    "            layers.append(nn.Sigmoid())\n",
    "            \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_nch, out_nch, nch, kernel=3, activation=\"ReLU\"):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            ConvolutionalBlock(in_nch, nch, kernel, activation),\n",
    "            ConvolutionalBlock(nch, nch*2, kernel, activation),\n",
    "            ConvolutionalBlock(nch*2, nch*4, kernel, activation),\n",
    "        )\n",
    "        self.fcs = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(4*4*(nch*4), out_nch),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fcs(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_test(net, testloader, device=\"cuda\", mode=\"eval\"):\n",
    "    if mode==\"train\":\n",
    "        net.train()\n",
    "    elif mode==\"eval\":\n",
    "        net.eval()\n",
    "    else:\n",
    "        return None\n",
    "    labels = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for itr, data in enumerate(testloader):\n",
    "            images = data[0].to(device)\n",
    "            label = cuda2numpy(data[1])\n",
    "            output = cuda2numpy(net(images))\n",
    "            if itr==0:\n",
    "                outputs = output\n",
    "            else:\n",
    "                np.concatenate([outputs, output], axis=0)\n",
    "                labels = np.append(labels, label)\n",
    "    return labels, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('linear') != -1:        \n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('batchnorm') != -1:     \n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_num = 301\n",
    "lr = 0.001\n",
    "save_parameter = False\n",
    "test_interval = 3\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_nch = 1\n",
    "out_nch = len(classes)\n",
    "nch = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Classifier(in_nch, out_nch, nch)\n",
    "net = net.to(device)\n",
    "net.apply(weights_init)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 6000)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----- adjustable parameters ----- #\n",
    "train_batch = 64\n",
    "val_batch = 64\n",
    "# --------------------------------- #\n",
    "\n",
    "dataset = Dataset_Fashion_MNIST(root, classes, \"train\", transform[\"train\"])\n",
    "dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=train_batch, shuffle=True)\n",
    "valset = Dataset_Fashion_MNIST(root, classes, \"val\", transform[\"train\"])\n",
    "valloader = torch.utils.data.DataLoader(dataset=valset, batch_size=val_batch, shuffle=True)\n",
    "len(dataset), len(valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-15cef13eb362>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-61e37083f577>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;31m#         image = torch.Tensor(np.reshape(min_max(image, mean0=False), (1, image.shape[0], -1)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/gonken-lesson/2021/Week_05/pyfiles/util.py\u001b[0m in \u001b[0;36mmin_max\u001b[0;34m(x, mean0)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmean0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "losses = []\n",
    "losses_epoch = []\n",
    "accs = []\n",
    "acc_epoch = []\n",
    "acc_test_list = []\n",
    "best_epoch = 0\n",
    "best_acc = 0\n",
    "for epoch in range(epoch_num):\n",
    "    for itr, data in enumerate(dataloader):\n",
    "        net.train()\n",
    "        x = data[0].to(device)\n",
    "        label = data[1].to(device)\n",
    "        opt.zero_grad()\n",
    "        y = net(x)\n",
    "        loss = criterion(y, label)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        loss = cuda2numpy(loss)\n",
    "        label = cuda2numpy(label)\n",
    "        y = cuda2numpy(y)\n",
    "        acc = (np.argmax(y, axis=1) == label).sum().item()/len(label)\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "    losses_epoch.append(np.mean(np.array(losses)))\n",
    "    acc_epoch.append(np.mean(np.array(accs)))\n",
    "    scheduler.step()\n",
    "    if epoch%test_interval==0:\n",
    "        labels, outputs = do_test_waveform(net, valloader, device, \"eval\")\n",
    "        pred_labels = np.argmax(outputs, axis=1) \n",
    "        acc_test = accuracy_score(labels, pred_labels)\n",
    "        acc_test_list.append(acc_test)\n",
    "        if best_acc < acc_test:\n",
    "            best_acc = acc_test\n",
    "            best_epoch = epoch\n",
    "            \n",
    "    clear_output(wait=True)\n",
    "    print(epoch)\n",
    "    print(f\"test acc in {epoch//test_interval*test_interval} : {acc_test}\")\n",
    "    print(f\"best acc is   : {best_acc} in epoch{best_epoch}\")\n",
    "    \n",
    "    if save_parameter:\n",
    "        if epoch%test_interval==0:\n",
    "            torch.save(net.state_dict(), \n",
    "                       f\"../instant_model_parameter/emorec_fs{fs}_{bi_or_uni}wavenet_precausal_nchin{nch_in}_prefilter{prefilter}_res_in{resnch_in}_hidden{resnch_hidden}_out{resnch_out}_nchhidden{nch_hidden}_nchout{nch_out}_wavenetln{layer_num}_fsize{filter_list[0]}_reduce{reduce}_cnnnum{num_cls}_input{target_length}_epoch{epoch}.pth\")\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    ax.plot(losses_epoch)\n",
    "    ax.set_title(\"loss\")\n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    ax.plot(acc_epoch, label=\"train\")\n",
    "    ax.plot(np.arange(epoch//test_interval+1)*test_interval, acc_test_list, label=\"val\")\n",
    "    ax.legend()\n",
    "    ax.set_title('accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- assignment\n",
    "    - implementation of ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
